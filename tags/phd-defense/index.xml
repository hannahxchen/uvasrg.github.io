<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PhD defense on Security Research Group</title>
    <link>//uvasrg.github.io/tags/phd-defense/</link>
    <description>Recent content in PhD defense on Security Research Group</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Privacy and Security Research at the University of Virginia</copyright>
    <lastBuildDate>Fri, 02 Dec 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="//uvasrg.github.io/tags/phd-defense/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Congratulations, Dr. Jayaraman!</title>
      <link>//uvasrg.github.io/congratulations-dr.-jayaraman/</link>
      <pubDate>Fri, 02 Dec 2022 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/congratulations-dr.-jayaraman/</guid>
      <description>Congratulations to Bargav Jayaraman for successfully defending his PhD thesis!
Dr. Jayaraman and his PhD committee: Mohammad&amp;nbsp;Mahmoody, Quanquan&amp;nbsp;Gu (UCLA Department of Computer Science, on screen), Yanjun&amp;nbsp;Qi (Committee Chair, on screen), Denis&amp;nbsp;Nekipelov (Department of Economics, on screen), and David Evans Bargav will join the Meta AI Lab in Menlo Park, CA as a post-doctoral researcher.
Analyzing the Leaky Cauldron: Inference Attacks on Machine Learning Machine learning models have been shown to leak sensitive information about their training data.</description>
    </item>
    <item>
      <title>Congratulations, Dr. Zhang!</title>
      <link>//uvasrg.github.io/congratulations-dr.-zhang/</link>
      <pubDate>Tue, 19 Jul 2022 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/congratulations-dr.-zhang/</guid>
      <description>Congratulations to Xiao Zhang for successfully defending his PhD thesis!
Dr. Zhang and his PhD committee: Somesh Jha (University of Wisconsin), David Evans, Tom Fletcher; Tianxi&amp;nbsp;Li&amp;nbsp;(UVA&amp;nbsp;Statistics), David&amp;nbsp;Wu&amp;nbsp;(UT&amp;nbsp;Austin), Mohammad&amp;nbsp;Mahmoody; Xiao&amp;nbsp;Zhang. Xiao will join the CISPA Helmholtz Center for Information Security in Saarbrücken, Germany this fall as a tenure-track faculty member.
From Characterizing Intrinsic Robustness to Adversarially Robust Machine Learning The prevalence of adversarial examples raises questions about the reliability of machine learning systems, especially for their deployment in critical applications.</description>
    </item>
    <item>
      <title>Congratulations Dr. Xu!</title>
      <link>//uvasrg.github.io/congratulations-dr.-xu/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/congratulations-dr.-xu/</guid>
      <description>Congratulations to Weilin Xu for successfully defending his PhD Thesis!
Weilin&#39;s Committee: Homa Alemzadeh, Yanjun Qi, Patrick McDaniel (on screen), David Evans, Vicente Ordóñez Román Improving Robustness of Machine Learning Models using Domain Knowledge Although machine learning techniques have achieved great success in many areas, such as computer vision, natural language processing, and computer security, recent studies have shown that they are not robust under attack. A motivated adversary is often able to craft input samples that force a machine learning model to produce incorrect predictions, even if the target model achieves high accuracy on normal test inputs.</description>
    </item>
  </channel>
</rss>
