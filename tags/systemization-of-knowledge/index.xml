<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>systemization of knowledge on Security Research Group</title>
    <link>//uvasrg.github.io/tags/systemization-of-knowledge/</link>
    <description>Recent content in systemization of knowledge on Security Research Group</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Privacy and Security Research at the University of Virginia</copyright>
    <lastBuildDate>Mon, 22 Apr 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="//uvasrg.github.io/tags/systemization-of-knowledge/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SaTML Talk: SoK: Pitfalls in Evaluating Black-Box Attacks</title>
      <link>//uvasrg.github.io/satml-talk-sok-pitfalls-in-evaluating-black-box-attacks/</link>
      <pubDate>Mon, 22 Apr 2024 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/satml-talk-sok-pitfalls-in-evaluating-black-box-attacks/</guid>
      <description>Anshuman Suri&amp;rsquo;s talk at IEEE Conference on Secure and Trustworthy Machine Learning (SaTML) is now available:&#xA;See the earlier blog post for more on the work, and the paper at https://arxiv.org/abs/2310.17534.</description>
    </item>
    <item>
      <title>SoK: Pitfalls in Evaluating Black-Box Attacks</title>
      <link>//uvasrg.github.io/sok-pitfalls-in-evaluating-black-box-attacks/</link>
      <pubDate>Wed, 20 Dec 2023 00:00:00 +0000</pubDate>
      <guid>//uvasrg.github.io/sok-pitfalls-in-evaluating-black-box-attacks/</guid>
      <description>Post by Anshuman Suri and Fnu Suya&#xA;Much research has studied black-box attacks on image classifiers, where adversaries generate adversarial examples against unknown target models without having access to their internal information. Our analysis of over 164 attacks (published in 102 major security, machine learning and security conferences) shows how these works make different assumptions about the adversaryâ€™s knowledge.&#xA;The current literature lacks cohesive organization centered around the threat model. Our SoK paper (to appear at IEEE SaTML 2024) introduces a taxonomy for systematizing these attacks and demonstrates the importance of careful evaluations that consider adversary resources and threat models.</description>
    </item>
  </channel>
</rss>
