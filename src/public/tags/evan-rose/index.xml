<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Evan Rose on Security Research Group</title>
    <link>//uvasrg.github.io/tags/evan-rose/</link>
    <description>Recent content in Evan Rose on Security Research Group</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Privacy and Security Research at the University of Virginia</copyright>
    <lastBuildDate>Tue, 26 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="//uvasrg.github.io/tags/evan-rose/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Visualizing Poisoning</title>
      <link>//uvasrg.github.io/visualizing-poisoning/</link>
      <pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>//uvasrg.github.io/visualizing-poisoning/</guid>
      <description>How does a poisoning attack work and why are some groups more susceptible to being victimized by a poisoning attack?
We&amp;rsquo;ve posted work that helps understand how poisoning attacks work with some engaging visualizations:
Poisoning Attacks and Subpopulation Susceptibility
An Experimental Exploration on the Effectiveness of Poisoning Attacks
Evan Rose, Fnu Suya, and David Evans
 Follow the link to try the interactive version!   Machine learning is susceptible to poisoning attacks in which adversaries inject maliciously crafted training data into the training set to induce specific model behavior.</description>
    </item>
    
  </channel>
</rss>
