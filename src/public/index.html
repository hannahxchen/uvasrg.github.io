<!doctype html>
<html class="no-js" lang="en-us">
  <head>
	<meta name="generator" content="Hugo 0.123.7">
    <meta charset="utf-8">
    <title>Security Research Group</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//uvasrg.github.io/css/foundation.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/fonts.css">
    <link rel="stylesheet" href="//uvasrg.github.io/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
  </script>
  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//uvasrg.github.io/">
		Security Research Group</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      
        <p class="groupstyle">Security and Privacy Research</br>at the University of Virginia</p>
	      
	    </div>
	  </div>
	</nav>
      
    </header>
    
    <main>
      





<div class="container">
 <div>

    <div class="column small-18 medium-9">
      
    <div class="content">

    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
           <center style="font-size:2rem; font-weight: 800;">
Security and Privacy Research at the University of Virginia
</center>
<p></p>
<div class="row">
    <div class="column medium-6">
        <p style="font-size: 1.3rem">
        Our research seeks to empower individuals and organizations to control
        how their data is used.  We use techniques from cryptography,
        programming languages, machine learning, operating systems, and other
        areas to both understand and improve the privacy and security of
        computing as practiced today, and as envisioned in the future. A major
        current focus is on <em>adversarial machine learning</em>.
        </p>
    </div>
    <div class="column medium-6">
        <center style="font-size: 1.5rem"> 
        <a
        href="/images/srglunch-2024-02-29.jpg"><img
        src="/images/srglunch-2024-02-29.jpg" alt="SRG lunch"
        width=90%></a><div text-align="center"><b>SRG Leap Day Lunch</b> <span style="font-size: 0.9rem; font-weight: 300">(29&nbsp;February&nbsp;2024)</span></div> <div
        style="font-size: 1.1rem; font-weight: 500">
        <a href="https://www.anshumansuri.com/">Anshuman&nbsp;Suri</a>,
        <a href="https://archit31uniyal.github.io/">Archit&nbsp;Uniyal</a>,
        <a href="https://elena6918.github.io/">Minjun&nbsp;Long</a>,
        Michael Jerge,
        <a href="https://hannahxchen.github.io/">Hannah&nbsp;Chen</a>,
        <a href="https://www.josephinelamp.com/">Josephine&nbsp;Lamp</a>
        </font> 
        </center>
    </div> 
</div>
<p></p>
<div class="row" style="padding-top: 12px">
    <div class="column medium-2">
        <a href="https://action.ucsb.edu/"><img src="/images/actionlogo.svg" width="100%" align="center"></a> 
    </div>
    <div class="column medium-10" style="font-size: 1.1rem">
    We are part of the <a href="https://action.ucsb.edu/">NSF AI Institute for Agent-based Cyber Threat Intelligence and Operation</a> (ACTION) which seeks to change the way mission-critical systems are protected against sophisticated security threats.  Collaboration with UC Santa Barbara (lead), Purdue, UC Berkeley, U Chicago, Georgia Tech, NSU, Rutgers, UIUC, UIC, UW, and WWU.
    </div>
</div>
<div class="row" style="padding-top: 12px; padding-bottom: 12px">
    <div class="column medium-10" style="font-size: 1.1rem">
        We are members of the <a href="https://ctml.psu.edu/">NSF SaTC Frontier Center for Trustworthy Machine Learning</a> (CTML) focused on
        developing a rigorous understanding of machine learning vulnerabilities  and producing tools, metrics, and methods to mitigate them. Collabortion with the University of Wisconsin (lead), UC Berkeley, UC San Diego, and Stanford. 
    </div>
        <div class="column medium-2">
    <a href="https://ctml.psu.edu/"><img src="/images/ctmllogo.png" width="90%" align="left"></a>
    </div>
</div>
<div class="row">
<div class="column small-10 medium-5">
<div class="mainsection">Active Projects</div>
<p><a href="/privacy/"><b>Privacy for Machine Learning</b></a> <br>
<a href="//www.evademl.org/"><b>Security for Machine Learning</b></a><br>
<b>Auditing ML Systems</b><br></p>
</div>
<div class="column small-14 medium-7">
<div class="mainsection">Past Projects</div>
<em>
<a href="//securecomputation.org">Secure Multi-Party Computation</a></em>:
<a href="//www.oblivc.org/">Obliv-C</a> &middot; <a href="//www.mightbeevil.org/">MightBeEvil</a><br>
<p><em>Web and Mobile Security</em>: <a href="/scriptinspector/">ScriptInspector</a> ·
<a href="http://www.ssoscan.org/">SSOScan</a><br>
<em>Program Analysis</em>: <a href="//www.splint.org/">Splint</a> · <a href="//www.cs.virginia.edu/perracotta">Perracotta</a><br>
<a href="//www.cs.virginia.edu/nvariant/">N-Variant Systems</a> ·
<a href="//www.cs.virginia.edu/physicrypt/">Physicrypt</a> ·
<a href="//www.cs.virginia.edu/evans/research.html">More&hellip;</a></p>
</p>
</div>
</div>

        
    
  

    <div class="mainsection">Recent Posts</div>

    
    <h2><a href="/googles-trail-of-crumbs/">Google&#39;s Trail of Crumbs</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2024-08-05 00:00:00 &#43;0000 UTC" itemprop="datePublished">5 August 2024</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/david-evans">David Evans</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/google">Google</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>Matt Stoller published my essay on Google&rsquo;s decision to abandon its Privacy Sandbox Initiative in his Big newsletter:</p>
<center>
<div class="substack-post-embed"><p lang="en">Google's Trail of Crumbs by Matt Stoller</p><p>Google is too big to get rid of cookies. Even when it wants to protect users, it can't.</p><a data-post-link href="https://www.thebignewsletter.com/p/googles-trail-of-crumbs">Read on Substack</a></div><script async src="https://substack.com/embedjs/embed.js" charset="utf-8"></script>
</center>
<p>For more technical background on this, see Minjun&rsquo;s paper: <a href="https://arxiv.org/abs/2405.08102"><em>Evaluating Google&rsquo;s Protected Audience Protocol</em></a> in PETS 2024.</p>

      </div>
<hr class="post-separator"></hr>

    
    <h2><a href="/technology-us-authorities-survey-ai-ecosystem-through-antitrust-lens/">Technology: US authorities survey AI ecosystem through antitrust lens</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2024-08-04 00:00:00 &#43;0000 UTC" itemprop="datePublished">4 August 2024</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/david-evans">David Evans</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/artificial-intelligence">artificial intelligence</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/machine-learning">machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/anti-trust">anti-trust</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>I&rsquo;m quoted in this article for the International Bar Association:</p>
<center>
<p><a href="https://www.ibanet.org/technology-us-authorities-survey-ai-ecosystem-through-antitrust-lens"><em>Technology: US authorities survey AI ecosystem through antitrust lens</em></a><br>
William Roberts, IBA US Correspondent<br>
Friday 2 August 2024</p>
</center>
<blockquote>
Antitrust authorities in the US are targeting the new frontier of artificial intelligence (AI) for potential enforcement action.
<p>&hellip;</p>
<p>Jonathan Kanter, Assistant Attorney General for the Antitrust Division of the DoJ, warns that the government sees ‘structures and trends in AI that should give us pause’. He says that AI relies on massive amounts of data and computing power, which can give already dominant companies a substantial advantage. ‘Powerful network and feedback effects’ may enable dominant companies to control these new markets, Kanter adds.</p>
<p>&hellip;</p>
<p>Part of the struggle for policymakers is that even defining AI is something of an unfathomable moving target, according to computer scientists. ‘What&rsquo;s different with AI is, this is making computers do things that no human understands how to do’, says David Evans, a professor of computer science at the University of Virginia who conducts research into machine learning. ‘Instead of humans working either individually or as a group to write a program, AI works by training an algorithm’, he explains.</p>
<p>New foundational AI systems such as ChatGPT&rsquo;s large language model are based on hundreds of billions of parameters and trained with everything on the internet and terabytes of material from other sources. Newer models are being trained in ways that are ten or 100 times more efficient. ‘Once you scale it up to the size of models that you&rsquo;re training, and the amount of data that you&rsquo;re using to train them, it is very hard to predict, or understand, or have any constraints on what they might do’, Evans says.</p>
<p>If anything, that opacity is encouraging the DoJ’s Antitrust Division to take a close look at the AI ecosystem. ‘Over and over again, we see that antitrust enforcement in moments of industrial evolution has the opportunity to spur innovation in its wake, opening the door to new competitors, allowing for the development of different business models and new economies’, Kanter says.</p>
</blockquote>
<p><a href="https://www.ibanet.org/technology-us-authorities-survey-ai-ecosystem-through-antitrust-lens">Full Article</a></p>

      </div>
<hr class="post-separator"></hr>

    
    <h2><a href="/congratulations-dr.-suri/">Congratulations, Dr. Suri!</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2024-07-18 00:00:00 &#43;0000 UTC" itemprop="datePublished">18 July 2024</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/anshuman-suri">Anshuman Suri</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/membership-inference">membership inference</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/distribution-inference">distribution inference</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/phd-defense">PhD defense</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/alina-oprea">Alina Oprea</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>Congratulations to <a href="https://www.anshumansuri.com/">Anshuman Suri</a> for successfully defending his <a href="https://libraetd.lib.virginia.edu/public_view/2227mr11j">PhD thesis</a>!</p>
<center>
<img src="/images/suri-phd.png" width="70%"><br>
Tianhao Wang, Dr. Anshuman Suri, Nando Fioretto, Cong Shen<br>
On Screen: David Evans, Giuseppe Ateniese
<br>
</center>
<h2 id="heading"></h2>
<h2 id="heading-1"></h2>
<center>
<em>
Inference Privacy in Machine Learning
</em>
</center>
<h2 id="heading-2"></h2>
<p>Using machine learning models comes at the risk of leaking information about data used in their training and deployment. This leakage can expose sensitive information about properties of the underlying data distribution, data from participating users, or even individual records in the training data. In this dissertation, we develop and evaluate novel methods to quantify and audit such information disclosure at three granularities: distribution, user, and record.</p>
<p>We begin with a formalization of inference privacy risks as cryptographic games and draw relations, such as reductions and separations, between various types of inference risks. We then propose a formal definition of distribution inference attacks that captures previous ratio-based property inference attacks as well as new kinds of attacks, and introduce a metric that quantifies observed leakage. We devise novel white-box and black-box distribution inference attacks and report on a series of experiments across a range of different distributions. We also evaluate the effectiveness of previously proposed defenses, finding that noise-based defenses are ineffective. Next, we estimate inference risk at the user level in Federated Learning scenarios with our attacks and demonstrate potent leakage. We also propose methods for injecting malicious behavior in the pre-training stage of a model, whereby selective parameters can be trained to activate differently on particular data to amplify distribution inference in downstream models. At the individual record level, we prove the necessity of parameter access for optimal membership inference, challenging the notion that black-box attacks suffice. Finally, we use membership inference to study memorization in Large Language Models (LLMs), observing near-random inference leakage for most settings, but revealing a connection between distribution inference and membership inference.</p>
<p>Our findings show that privacy leakage spans a spectrum of granularities, making it essential to consider multiple forms of leakage. Ultimately, our work underscores the urgent need for robust privacy-preserving techniques to mitigate these multifaceted risks in machine learning systems.</p>
<p>Dissertation: <a href="https://libraetd.lib.virginia.edu/public_view/2227mr11j"><em>Inference Privacy in Machine Learning</em></a></p>
<p><a href="https://engineering.virginia.edu/news-events/events/phd-defense-presentation-anshuman-suri">Presentation Announcement</a></p>
<p><a href="https://x.com/iamgroot42/status/1814033241688428695">Twitter</a></p>
<h1 id="heading-3"></h1>
<p>Dr. Suri will start a post-doc with <a href="https://www.khoury.northeastern.edu/home/alina/">Alina Oprea</a> at Northeastern University this fall.</p>
<h1 id="heading-4"></h1>
<p><strong>Committee:</strong></p>
<p>Tianhao Wang (Committee Chair, Computer Science)<br>
David Evans (Advisor, Computer Science)<br>
Nando Fioretto (Computer Science)<br>
Cong Shen (Electrical and Computer Engineering)<br>
Giuseppe Ateniese (George Mason University)</p>

      </div>
<hr class="post-separator"></hr>

    
    <h2><a href="/graduation-2024/">Graduation 2024</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2024-05-29 00:00:00 &#43;0000 UTC" itemprop="datePublished">29 May 2024</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/josephine-lamp">Josephine Lamp</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/graudation">graudation</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <center>
<a href="/images/graduation2024/PXL_20240517_175539174-fish.jpg""><img src="/images/graduation2024/PXL_20240517_175539174-fish.jpg" width="85%"></img></a>
</center>
<center>
<h1 id="congratulations-to-our-two-phd-graduates">Congratulations to our two PhD graduates!</h1>
</center>
<p>Suya will be joining the University of Tennessee at Knoxville as an Assistant Professor.</p>
<p>Josie will be building a medical analytics research group at Dexcom.</p>
<center>
<a href="/images/graduation2024/IMG_5973.png"><img src="/images/graduation2024/IMG_5973.png" width="85%"></img></a>
</center>
<h2 id="heading"></h2>
<center>
<a href="/images/graduation2024/IMG_5941.png"><img src="/images/graduation2024/IMG_5941.png" width="60%"></img></a>
&nbsp;<a href="/images/graduation2024/IMG_5951.png"><img src="/images/graduation2024/IMG_5951.png" width="60%"></img></a>&nbsp;
<a href="/images/graduation2024/IMG_5962.png"><img src="/images/graduation2024/IMG_5962.png" width="60%"></img></a>
</center>

      </div>
<hr class="post-separator"></hr>

    
    <h2><a href="/satml-talk-sok-pitfalls-in-evaluating-black-box-attacks/">SaTML Talk: SoK: Pitfalls in Evaluating Black-Box Attacks</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2024-04-22 00:00:00 &#43;0000 UTC" itemprop="datePublished">22 April 2024</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//uvasrg.github.io/tags/fnu-suya">Fnu Suya</a>,</span> 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/anshuman-suri">Anshuman Suri</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/tingwei-zhang">Tingwei Zhang</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/jingtao-hong">Jingtao Hong</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/yuan-tian">Yuan Tian</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/david-evans">David Evans</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/satml">SaTML</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/adversarial-machine-learning">adversarial machine learning</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/black-box-adversarial-attacks">black-box adversarial attacks</a>, 
    
    <a class="post-tag" href="//uvasrg.github.io/tags/systemization-of-knowledge">systemization of knowledge</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p><a href="https://www.anshumansuri.com/">Anshuman Suri</a>&rsquo;s talk at <a href="https://satml.org/">IEEE Conference on Secure and Trustworthy Machine Learning</a> (SaTML) is now available:</p>
<center>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ui4HMGe3aUs?si=M2A-uD77s4BdhXPR" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</center>
<p>See the <a href="https://uvasrg.github.io/sok-pitfalls-in-evaluating-black-box-attacks/">earlier blog post</a> for more on the work, and the paper at <a href="https://arxiv.org/abs/2310.17534">https://arxiv.org/abs/2310.17534</a>.</p>

      </div>
<hr class="post-separator"></hr>

    


    <footer>
      <nav>
	<a href="/post/" class="button hollow primary">All Posts</a>
      </nav>
    </footer>
   </div>
    </div>

    <div class="column small=7 medium-3">
    <div class="sidebar">
<center>                  <img src="/images/srg-logo-scaled.png" width=200 height=200 alt="SRG Logo">
      University of Virginia <br>
Security Research Group
</center>

</p>
   <p>
   <a href="/team"><b>Team</b></a></br>
   <a href="//www.cs.virginia.edu/evans/pubs"><b>Publications</b></a><br>
      <a href="/videos"><b>Videos</b></a><br>
   </p>
<p class="nogap">
     <p>
   <a href="https://teams.microsoft.com/l/team/19%3aWdkw2xYq6taXh-0OftqQdt8SQ2vyvUI_Z0ZL39APghY1%40thread.tacv2/conversations?groupId=58076b41-c835-4a07-abaa-705bc7cca101&tenantId=7b3480c7-3707-4873-8b77-e216733a65ac"><b>Join Teams Group</b></a>
   </p>

  <a href="/studygroups/"><b>Study Groups</b></a>

  

<p class="nogap"></p>
  <p>
   <b><a href="/post/">Recent News</a></b>
   </p>
   
   <div class="posttitle">
      <a href="/googles-trail-of-crumbs/">Google&#39;s Trail of Crumbs</a>


   </div>
   
   <div class="posttitle">
      <a href="/technology-us-authorities-survey-ai-ecosystem-through-antitrust-lens/">Technology: US authorities survey AI ecosystem through antitrust lens</a>


   </div>
   
   <div class="posttitle">
      <a href="/congratulations-dr.-suri/">Congratulations, Dr. Suri!</a>


   </div>
   
   <div class="posttitle">
      <a href="/graduation-2024/">Graduation 2024</a>


   </div>
   
   <div class="posttitle">
      <a href="/satml-talk-sok-pitfalls-in-evaluating-black-box-attacks/">SaTML Talk: SoK: Pitfalls in Evaluating Black-Box Attacks</a>


   </div>
   
   <div class="posttitle">
      <a href="/congratulations-dr.-lamp/">Congratulations, Dr. Lamp!</a>


   </div>
   
   <div class="posttitle">
      <a href="/do-membership-inference-attacks-work-on-large-language-models/">Do Membership Inference Attacks Work on Large Language Models?</a>


   </div>
   
   <div class="posttitle">
      <a href="/sok-pitfalls-in-evaluating-black-box-attacks/">SoK: Pitfalls in Evaluating Black-Box Attacks</a>


   </div>
   
   <div class="posttitle">
      <a href="/neurips-2023-what-distributions-are-robust-to-poisoning-attacks/">NeurIPS 2023: What Distributions are Robust to Poisoning Attacks?</a>


   </div>
   
   <div class="posttitle">
      <a href="/adjectives-can-reveal-gender-biases-within-nlp-models/">Adjectives Can Reveal Gender Biases Within NLP Models</a>


   </div>
   
   <div class="posttitle">
      <a href="/congratulations-dr.-suya/">Congratulations, Dr. Suya!</a>


   </div>
   
   <div class="posttitle">
      <a href="/sok-let-the-privacy-games-begin-a-unified-treatment-of-data-inference-privacy-in-machine-learning/">SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning</a>


   </div>
   
   <div class="posttitle">
      <a href="/cvpr-2023-manipulating-transfer-learning-for-property-inference/">CVPR 2023: Manipulating Transfer Learning for Property Inference</a>


   </div>
   
   <div class="posttitle">
      <a href="/voice-of-america-interview-on-chatgpt/">Voice of America interview on ChatGPT</a>


   </div>
   
   <div class="posttitle">
      <a href="/mico-challenge-in-membership-inference/">MICO Challenge in Membership Inference</a>


   </div>
   
   <div class="posttitle">
      <a href="/uh-oh-theres-a-new-way-to-poison-code-models/">Uh-oh, there&#39;s a new way to poison code models</a>


   </div>
   
   <div class="posttitle">
      <a href="/trojan-puzzle-attack-trains-ai-assistants-into-suggesting-malicious-code/">Trojan Puzzle attack trains AI assistants into suggesting malicious code</a>


   </div>
   
   <div class="posttitle">
      <a href="/dissecting-distribution-inference/">Dissecting Distribution Inference</a>


   </div>
   
   <div class="posttitle">
      <a href="/cray-distinguished-speaker-on-leaky-models-and-unintended-inferences/">Cray Distinguished Speaker: On Leaky Models and Unintended Inferences</a>


   </div>
   
   <div class="posttitle">
      <a href="/attribute-inference-attacks-are-really-imputation/">Attribute Inference attacks are really Imputation</a>


   </div>
   
   <div class="posttitle">
      <a href="/congratulations-dr.-jayaraman/">Congratulations, Dr. Jayaraman!</a>


   </div>
   
   <div class="posttitle">
      <a href="/balancing-tradeoffs-between-fickleness-and-obstinacy-in-nlp-models/">Balancing Tradeoffs between Fickleness and Obstinacy in NLP Models</a>


   </div>
   
   <div class="posttitle">
      <a href="/best-submission-award-at-visxai-2022/">Best Submission Award at VISxAI 2022</a>


   </div>
   
   <div class="posttitle">
      <a href="/visualizing-poisoning/">Visualizing Poisoning</a>


   </div>
   
   <div class="posttitle">
      <a href="/congratulations-dr.-zhang/">Congratulations, Dr. Zhang!</a>


   </div>
   
<p></p>
   <div class="posttitle"><a href="/post/">Older Posts</a></div>
  <div class="posttitle"><a href="/tags">Posts by Tag</a></div>
  <div class="posttitle"><a href="/categories/">Posts by Category</a></div>
  <div class="posttitle"><a href="2017.html">Old Blog</a></div>
<p></p>
<p>
<a href="/awards/"><b>Awards</b></a>
</p>

   <p>
Director: <a href="//www.cs.virginia.edu/evans">David Evans</a>
   </p>

<p>

  </p>

<p><br></br></p>

   <p>
     <center>
       <img src="/images/uva_primary_rgb_white.png" width="80%">
       </center>
</p>

    </div>
</div>

   </div>


    </main>
    
    
    <footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-8 medium-4">
      
      <a href="/"><img src="/images/srg-logo-scaled.png" width=100 height=100 alt="SRG Logo" align="left"> <b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
    </div>
    <div class="column small-6 medium-3">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//uvasrg.github.io/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>

    
    
    <div class="endofpage">
    </div>

    <script src="/js/jquery-3.7.0.slim.min.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
