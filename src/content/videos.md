Some selected talk videos on our research. See [David Evans - Videos](https://www.cs.virginia.edu/~evans/videos/) for more videos.

<a href="https://uvasrg.github.io/iclr-dpml-2021-inference-risks-for-machine-learning/"><b>Inference
    Risks for Machine Learning</b></a>
<blockquote>

Invited talk at
the <a href="https://dp-ml.github.io/2021-workshop-ICLR/">Distributed
    and Private Machine Learning</a> (DPML) workshop at ICLR 2021, 7 May
2021. [<a href="https://www.youtube.com/watch?v=zgSTsO1LKSs">Video</a>]

</blockquote>

<center>
<iframe width="560" height="315"
	src="https://www.youtube-nocookie.com/embed/zgSTsO1LKSs"
	title="YouTube video player" frameborder="0"
	allow="accelerometer; autoplay; clipboard-write;
	encrypted-media; gyroscope; picture-in-picture"
	allowfullscreen></iframe>
</center>

<a href="https://crysp.uwaterloo.ca/speakers/20210329-Evans"><b>When Models Learn Too Much</b></a>
<blockquote>
CrySP Speaker Series on Privacy, University of Waterloo, 29 March
2021. [<a href="https://crysp.uwaterloo.ca/speakers/20210329-Evans">Abstract</a>] [<a href="https://www.youtube.com/watch?v=LM_-N76_KIw">Video</a>]
</blockquote>

<center>
<iframe width="560" height="315"
	src="https://www.youtube-nocookie.com/embed/LM_-N76_KIw"
	title="YouTube video player" frameborder="0"
	allow="accelerometer; autoplay; clipboard-write;
	encrypted-media; gyroscope; picture-in-picture"
	allowfullscreen></iframe>
</center>

Suya's presentation on [**Hybrid Batch Attacks**](/usenix-security-2020-hybrid-batch-attacks) at USENIX Security 2020:

<center>
  <video width="90%" id="usenix-media-video-1" data-setup="{}" poster="" class="video-js vjs-default-skin vjs-big-play-centered" preload="auto" controls>
    <source src='https://2459d6dc103cb5933875-c0245c5c937c5dedcca3f1764ecc9b2f.ssl.cf2.rackcdn.com/sec20/videos/0813/s5_machine_learning_1/3_sec20summer-paper412-presentation-video.mp4' type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'>
  </video><br> 
<a href="https://2459d6dc103cb5933875-c0245c5c937c5dedcca3f1764ecc9b2f.ssl.cf2.rackcdn.com/sec20/videos/0813/s5_machine_learning_1/3_sec20summer-paper412-presentation-video.mp4">Download Video [mp4]</a></p>
([Blog Post](/usenix-security-2020-hybrid-batch-attacks)  
Paper: [[PDF](/docs/hybrid_attack.pdf)]&nbsp;[[arXiv](https://arxiv.org/abs/1908.07000)] 
([Blog Post](/usenix-security-2020-hybrid-batch-attacks), Paper: [[PDF](/docs/hybrid_attack.pdf)]&nbsp;[[arXiv](https://arxiv.org/abs/1908.07000)] )
</center>

Xiao Zhang's presentation
on <A href="/neurips-2019-empirically-measuring-concentration/"><b>Empirically Measuring Concentration</b></a> at NeurIPS 2019: <br>
<a href="https://slideslive.com/38921718/track-2-session-1"><em>https://slideslive.com/38921718/track-2-session-1</em></a> (starting at 26:50)
</p>
<center>
<a href="/images/NeurIPS2019/IMG_6759.JPG"><img src="/images/NeurIPS2019/IMG_6759.JPG" width="75%"></a><br>
</center>

Bargav Jayaraman's talk on <a href="/evaluating-differentially-private-machine-learning-in-practice/"><b>Evaluating Differentially Private Machine Learning in Practice</b></a> at USENIX Security 2019:
<center>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/JAGhqbY_U50" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

<a href="https://vid.umd.edu/detsmediasite/Play/e8009558850944bfb2cac477f8d741711d?catalog=74740199-303c-49a2-9025-2dee0a195650"><b>Can
    Machine Learning Ever Be Trustworthy?</b></a>
<blockquote>
University of
Maryland, <a href="https://ece.umd.edu/events/distinguished-colloquium-series">Booz
    Allen Hamilton Distinguished Colloquium</a>. 7&nbsp;December&nbsp;2018. 
[<a href="https://speakerdeck.com/evansuva/can-machine-learning-ever-be-trustworthy">SpeakerDeck</a>]
[<a href="https://vid.umd.edu/detsmediasite/Play/e8009558850944bfb2cac477f8d741711d?catalog=74740199-303c-49a2-9025-2dee0a195650">Video</a>]
</blockquote>

<a href="#dls">
<a href="/evans/talks/dls2018/"><b>
Is "adversarial examples" an Adversarial Example?</b></a><br>
<blockquote>
Keynote talk at <a
href="https://www.ieee-security.org/TC/SPW2018/DLS/#"><em>1st Deep
Learning and Security Workshop</em></a> (Co-located with the 39th
<em>IEEE Symposium on Security and Privacy</em>). San Francisco,
California. 24 May 2018. [<a href="https://speakerdeck.com/evansuva/is-adversarial-examples-an-adversarial-example">SpeakerDeck</a>]
</blockquote>
<center>
<iframe width="640" height="360"
	src="https://www.youtube-nocookie.com/embed/sFhD6ABghf8?rel=0"
	frameborder="0" allow="autoplay; encrypted-media"
	allowfullscreen></iframe><br>
</center>
</p>
<p>
<a name="#enigma">
<a href="https://www.jeffersonswheel.org/2017/enigma-2017-talk-classifiers-under-attack"><b>Classifiers Under Attack</b></a><br>
<blockquote>
<a href="https://www.usenix.org/conference/enigma2017/conference-program/presentation/evans">USENIX
  Enigma 2017</a>, Oakland, CA, 1 February
  2017. [<A href="https://speakerdeck.com/evansuva/classifiers-under-attack-1">Speaker Deck</a>] [<a href="https://evademl.org">EvadeML</a>]
</blockquote>
<center>
<iframe width="640" height="360" src="https://www.youtube.com/embed/XYJamxDROOs" frameborder="0" allowfullscreen></iframe>
</center>

