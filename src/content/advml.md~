# Adversarial Machine Learning Study Group


Meetings on Mondays, 11am (Summer 2020)

Leaders: <a href="https://hannahxchen.github.io/">Hannah Chen</a>, <a href="https://sites.google.com/virginia.edu/anshuman/home">Anshuman Suri</a>


   <table width="100%" align="center">
   <tr bgcolor="#CCC"><td style="text-align:center" width="35%"><b>Date</b></td><td width="65%" style="text-align:center"><b>Topic</b></td></tr>
   <tr bgcolor="#FFF"><td>25 May 2020</td><td>
Nicolas Carlini, <a href="https://www.youtube.com/watch?v=ZncTqqkFipE"><em>Lessons Learned from Evaluating the Robustness of Defenses to Adversarial Examples</em></a> (USENIX Security 2019)
</td></tr>
   <tr bgcolor="#BDF">
   <td>
1 June 2020
   </td><td>
Aleksander Madry, <a href="https://simons.berkeley.edu/talks/tbd-57"><em>A New Perspective on Adversarial Perturbations</em></a> (Simons Institute, July 2019)  
   </td>
   </tr>

   <tr>
   <td>22 June 2020</td>
   <td>Nicholas Carlini, <a href="https://www.youtube.com/watch?&v=U9XbFtCWedE"><em>The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks</em></a> (USENIX Security 2019)</td>
   </tr>

   </table>

   </div>
   <div class="column small-14 medium-7">
