+++
date = "07 May 2021"
draft = false
title = "ICLR DPML 2021: Inference Risks for Machine Learning"
author = "David Evans"
categories = ["talks"]
tags = ["adversarial machine learning", "privacy", "Bargav Jayaraman", "Anshuman Suri", "Katherine Knipmeyer", "inference privacy", "privacy", "privacy-preserving machine learning"]
+++

Here are the slides for my talk at the
[11th ACM Conference on Data and Application Security and Privacy](http://www.codaspy.org/2021/program.html):
   <center>
<a href="https://www.dropbox.com/s/6wzloxuai709s0k/codaspy-post.pdf?dl=0)"><b>When Models Learn Too Much</b> [PDF]</a>
   </center>

##

The talk includes Bargav Jayaraman's work (with Katherine Knipmeyer, Lingxiao Wang, and Quanquan Gu) on evaluating privacy in machine learning (as well as more recent work by Anshuman Suri on property inference attacks, and Bargav on attribute inference and imputation): 

- [_Merlin, Morgan, and the Importance of Thresholds and Priors_](/merlin-morgan-and-the-importance-of-thresholds-and-priors/)
- [_Evaluating Differentially Private Machine Learning in Practice_](/evaluating-differentially-private-machine-learning-in-practice/)

<center>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">“When models learn too much. “ Dr. David Evans <a href="https://twitter.com/UdacityDave?ref_src=twsrc%5Etfw">@UdacityDave</a> of University of Virginia gave a keynote talk on different inference risks for machine learning models this morning at <a href="https://twitter.com/hashtag/codaspy21?src=hash&amp;ref_src=twsrc%5Etfw">#codaspy21</a> <a href="https://t.co/KVgFoUA6sa">pic.twitter.com/KVgFoUA6sa</a></p>&mdash; acmcodaspy (@acmcodaspy) <a href="https://twitter.com/acmcodaspy/status/1386748565796507652?ref_src=twsrc%5Etfw">April 26, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>

