+++
date = "26 Apr 2021"
draft = false
title = "Codaspy 2021 Keynote: When Models Learn Too Much"
author = "David Evans"
categories = ["talks"]
tags = ["adversarial machine learning", "privacy", "Bargav Jayaraman", "Anshuman Suri", "Katherine Knipmeyer", "inference privacy", "privacy", "privacy-preserving machine learning"]
+++

Here are the slides for my talk at the
[11th ACM Conference on Data and Application Security and Privacy](http://www.codaspy.org/2021/program.html):
[_When Models Learn Too Much_ [PDF]](https://www.dropbox.com/s/6wzloxuai709s0k/codaspy-post.pdf?dl=0)

<center>
<a href="https://www.dropbox.com/s/698cuvee81clx1q/inference-privacy-share.pdf?dl=0">
<img src="/images/inferenceprivacytitle.png" width=65%>
</a>
</center>

The includes Bargav Jayaraman's work (with Katherine Knipmeyer, Lingxiao Wang, and Quanquan Gu) on evaluating privacy in machine learning (as well as more recent work by Anshuman Suri on property inference attacks, and Bargav on attribute inference and imputation): 

- [_Merlin, Morgan, and the Importance of Thresholds and Priors_](/merlin-morgan-and-the-importance-of-thresholds-and-priors/)
- [_Evaluating Differentially Private Machine Learning in Practice_](/evaluating-differentially-private-machine-learning-in-practice/)

