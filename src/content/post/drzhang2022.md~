+++
date = "19 Jul 2022"
draft = false
title = "BIML: What Machine Learnt Models Reveal"
author = "David Evans"
categories = ["talks"]
tags = ["BIML", "privacy-preserving machine learning", "distribution inference", "inference privacy", "Gary McGraw"]
+++

I gave a talk in the [Berryville Institute of Machine Learning in the Barn](https://berryvilleiml.com/) series on _What Machine Learnt Models Reveal_, which is now available as an edited video:

<center>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/zMM_y6VWSgA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

> David Evans, a professor of computer science researching security and privacy at the University of Virginia, talks about data leakage risk in ML systems and different approaches used to attack and secure models and datasets. Juxtaposing adversarial risks that target records and those aimed at attributes, David shows that differential privacy cannot capture all inference risks, and calls for more research based on privacy experiments aimed at both datasets and distributions.

The talk is mostly about inference privacy work done by Anshuman Suri and Bargav Jayaraman.
