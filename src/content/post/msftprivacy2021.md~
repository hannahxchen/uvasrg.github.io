+++
date = "21 Oct 2021"
draft = false
title = "Microsoft Research Summit: Surprising (and unsurprising) Inference Risks in Machine Learning"
author = "David Evans"
categories = ["talks"]
tags = ["adversarial machine learning", "privacy", "Bargav Jayaraman", "Anshuman Suri", "Katherine Knipmeyer", "inference privacy", "privacy", "privacy-preserving machine learning"]
+++

Here are the slides for my talk at the [_Practical and Theoretical Privacy of Machine Learning Training Pipelines_](https://www.microsoft.com/en-us/research/theme/confidential-computing/#workshops)
Workshop at the Microsoft Research Summit (21 October 2021):
   <center>
<a href="https://www.dropbox.com/s/1mfhbelv7qx4t3u/surprisinginferences.pdf?dl=0"><b>Surprising (and unsurprising) Inference Risks in Machine Learning"</b> [PDF]</a>
   </center>

##

The work by Bargav Jayaraman (with Katherine Knipmeyer, Lingxiao Wang,
and Quanquan Gu) that I talked about on improving membership inference
attacks is described in more details here:

- [_Merlin, Morgan, and the Importance of Thresholds and Priors_](/merlin-morgan-and-the-importance-of-thresholds-and-priors/)
- [_Evaluating Differentially Private Machine Learning in Practice_](/evaluating-differentially-private-machine-learning-in-practice/)

The work on distribution inference is described in this paper (by Anshuman Suri):

- [_Formalizing and Estimating Distribution Inference Risks_](https://arxiv.org/abs/2109.06024) [Blog Summary](https://uvasrg.github.io/on-the-risks-of-distribution-inference/) [Code: [https://github.com/iamgroot42/form_est_dist_risks](https://github.com/iamgroot42/form_est_dist_risks)]




