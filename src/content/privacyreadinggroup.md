# Privacy Reading Group

Meetings on **Tuesdays, 11am** (Summer 2020)

Leader: <a href="https://bargavjayaraman.github.io/">Bargav Jayaraman</a>  

   <table width="100%" align="center">
   <tr bgcolor="#CCC"><td style="text-align:center" width="25%"><b>Date</b></td><td width="75%" style="text-align:center"><b>Topic/Talk</b></td></tr>

   <tr bgcolor="#FFF"><td>26 May 2020</td><td>
Cynthia Dwork, <a href="https://www.youtube.com/watch?v=vsA4w3itxA0"><em>Privacy-Preserving Data Analysis</em></a> (Alan Turing Institute, Turing Lecture, Dec 2016)
  </td></tr>
   <tr bgcolor="#BDF">
   <td>
   2 June 2020
   </td><td>
Guy Rothblum, <a href="https://www.youtube.com/watch?v=RNqZJDAP1uU"><em>Composition: The Key to Differential Privacy is Success</em></a> (Institute for Advanced Study, Nov 2016)
   </td>
   </tr>

   <tr bgcolor="#FFF">
   <td>9 June 2020</td>
   <td>

Yuxin Wang, <a href="https://www.youtube.com/watch?v=qGgCdsxTbkM"><em>Detecting Violations of Differential Privacy</em></a> (ACM CCS 2018)

Benjamin Bichsel, <a href="https://www.youtube.com/watch?v=Jwe0oCSlaMk"><em>DP-Finder: Finding Differential Privacy Violations by Sampling and Optimization</em></a> (ACM CCS 2018)

   </td>
   </tr>

   <tr bgcolor="#BDF">
   <td>
   15 June 2020</td>
   <td>
(Joint with <a href="/advml"><em>Adversarial Machine Learning Study Group</em></a>)

Mathias Lécuyer, <a href="https://www.youtube.com/watch?v=mYRdZIXtqcA"><em>Certified Robustness to Adversarial Examples with Differential Privacy</em></a> (IEEE Security and Privacy 2019)

Liwei Song, <a href="https://www.youtube.com/watch?v=MUhb3bRla2A"><em>Membership Inference Attacks against Adversarially Robust Deep Learning Models</em></a> (IEEE Security and Privacy 2019)

</td>
</tr>
   <tr bgcolor="#FFF">
   <td>23 June 2020</td>
   <td>

Reza Shokri, <a href="https://www.youtube.com/watch?v=rDm1n2gceJY"><em>Membership Inference Attacks against Machine Learning Models</em></a> (IEEE Security and Privacy 2017)

   Nicholas Carlini, <a href="https://www.youtube.com/watch?&v=U9XbFtCWedE"><em>The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks</em></a> (USENIX Security 2019) 
   </td>
   </tr>

   <tr bgcolor="#BDF">
   <td>30 June 2020</td>
   <td>


Karan Ganju, <a href="https://www.youtube.com/watch?v=99YHPIsKzCc"><em>Property Inference Attacks on Fully Connected Neural Networks</em></a> (ACM CCS 2019)

Binghui Wang, <a href="https://www.youtube.com/watch?v=rpRVqfjW0AA"><em>Stealing Hyperparameters in Machine Learning</em></a> (IEEE Security and Privacy 2018)
</td>
</tr>

   <tr bgcolor="#FFF">
   <td>7 July 2020</td>
   <td>

Joe Near, <a href="https://www.youtube.com/watch?v=pk_DCSUayDA"><em>Differential Privacy at Scale: Uber and Berkeley Collaboration</em></a> (USENIX Enigma 2020) (also see Frank McSherry's <a href="https://github.com/uber-archive/sql-differential-privacy/issues/1">github issue</a> and <a href="https://github.com/frankmcsherry/blog/blob/master/posts/2018-02-25.md">blog post</a>)


Brendan McMahan, <a href="https://www.youtube.com/watch?v=e5othcNmync"><em>Guarding user Privacy with Federated Learning and Differential Privacy</em></a> (DIMACS, 2017)

</td>
</tr>

   <tr bgcolor="#BDF">
   <td>14 July 2020</td>
   <td>

Ilya Mironov, <A href="https://www.youtube.com/watch?v=oQzaA5KG3pM"><em>Rényi Differential Privacy</em></a> (DIMACS, 2017)

</td>
</tr>

   </table>
