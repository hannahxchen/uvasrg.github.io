# Adversarial Machine Learning Study Group


Meetings on Mondays, 11am (Summer 2020)

Leaders: <a href="https://hannahxchen.github.io/">Hannah Chen</a>, <a href="https://sites.google.com/virginia.edu/anshuman/home">Anshuman Suri</a>


   <table width="100%" align="center">
   <tr bgcolor="#CCC"><td style="text-align:center" width="25%"><b>Date</b></td><td width="75%" style="text-align:center"><b>Topic/Talk</b></td></tr>
   <tr bgcolor="#FFF"><td>25 May 2020</td><td>
Nicolas Carlini, <a href="https://www.youtube.com/watch?v=ZncTqqkFipE"><em>Lessons Learned from Evaluating the Robustness of Defenses to Adversarial Examples</em></a> (USENIX Security 2019)
</td></tr>
   <tr bgcolor="#BDF">
   <td>
1 June 2020
   </td><td>
Aleksander Madry, <a href="https://simons.berkeley.edu/talks/tbd-57"><em>A New Perspective on Adversarial Perturbations</em></a> (Simons Institute, July 2019)  
   </td>
   </tr>

   <tr bgcolor="#FFF">
   <td>8 June 2020</td>
   <td>

Sadia Afroz, <a href="https://www.youtube.com/watch?v=wGrCyAtojvg"><em>How to Build Realistic Machine Learning Systems for Security?</em></a> (USENIX Enigma 2020)

Ji Gao, <a href="https://www.youtube.com/watch?v=Ho3V_eACoSQ"><em>Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers</em></a> (Deep Learning and Security Workshop 2018)   </td>
   </tr>

   <tr bgcolor="#BDF">
   <td>
   15 June 2020</td>
   <td>
(Joint with <a href="/privacy"><em>Privacy Study Group</em></a>)

Mathias LÃ©cuyer, <a href="https://www.youtube.com/watch?v=mYRdZIXtqcA"><em>Certified Robustness to Adversarial Examples with Differential Privacy</em></a> (IEEE Security and Privacy 2019)

Liwei Song, <a href="https://www.youtube.com/watch?v=MUhb3bRla2A"><em>Membership Inference Attacks against Adversarially Robust Deep Learning Models</em></a> (IEEE Security and Privacy 2019)

</td>
</tr>
   <tr>
   <td>22 June 2020</td>
   <td>

Yujie Ji, <a href="https://www.youtube.com/watch?v=Zsd-IB3TWrA"><em>Model-Reuse Attacks on Deep Learning Systems</em></a> (ACM CCS 2018)

Roei Schuster, <a href="https://www.youtube.com/watch?v=lg3NrnxGsiU&feature=youtu.be"><em>Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning</em></a> (IEEE Security and Privacy 2020)


</td>
   </tr>

   </table>

Join [our slack group](https://uvasrg.slack.com) for announcements about future meetings.